#!/bin/sh
#SBATCH --partition=allgpu             ## or allgpu / cms / cms-uhh / maxgpu
#SBATCH --time=24:00:00
#SBATCH --nodes=1
#SBATCH --job-name image_utils           # give job unique name
#SBATCH --output ./img_log/%j-std.out      # terminal output
#SBATCH --error ./img_log/%j-std.err
#S BATCH --mail-type END
#S BATCH --mail-user lennart.kaemmle@desy.de
#SBATCH --constraint=GPU

# #SBATCH --nodelist=max-cmsg004         # you can select specific nodes, if necessary
# #SBATCH --constraint="P100|V100"        # ask for specific types of GPUs

# (GPU drivers, anaconda, .bashrc, etc) --> likely not necessary if you're installing your own cudatoolkit & cuDNN versions
#source /etc/profile.d/modules.sh
#module load maxwell
#module load cuda
#module load anaconda/3
#module load mpi/mpich-x86_64
module load mpi/openmpi3-x86_64

. ~/.bashrc
export PATH="/home/kaemmlel/miniconda3/envs/torch/bin:$PATH"

set -x
# export PATH="/home/kaemmlel/miniconda3/envs/torch/bin:$PATH"
export PYTHONPATH=""  # openmpi module adds python 2 packages to pythonpath

# go to your folder with your python scripts
cd ~/Projects/amazing_ai

# run
#        --sigma 0.6 \
#        --blur_size 15 \
#        --blur \
# -o "@{basename}_images_{npix}_cutoff={cutoff}_sigma={sigma}_bs={blur_size}{flags}.h5" \
MPI4PY_RC_THREADS=0 time mpirun --use-hwthread-cpus \
    python -m amazing_ai.image_utils \
        -i @events_s_sr.h5 \
        -o "@{basename}_images_{npix}{flags}_hist.h5" \
        --npix 42 \
        --mpi \
        --center
#        --flip \
#        --rotate
        # --cutoff -10 \
